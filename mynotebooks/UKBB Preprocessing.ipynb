{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get attributes and reformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_path = '' # get all relevant baseline characterisitcs and attributes from ukbb showcase and save as txt file, '/well/papiez/shared/UKBB/shared/21015_baseline_characteristics.txt'\n",
    "image_folder = '' # path to the folder containing the images. '/well/papiez/shared/UKBB/DataField_21015/'\n",
    "train_imgs_path = '' # where to save train imgs\n",
    "val_imgs_path = '' # where to save val imgs\n",
    "test_imgs_path = '' # where to save test imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess relevant attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87540\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image.id</th>\n",
       "      <th>eid</th>\n",
       "      <th>image.instance</th>\n",
       "      <th>image.array</th>\n",
       "      <th>age_at_imaging</th>\n",
       "      <th>genetic_sex</th>\n",
       "      <th>bmi_at_imaging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000058_21015_1_0.png</td>\n",
       "      <td>1000058</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>63.824176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000075_21015_0_0.png</td>\n",
       "      <td>1000075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000083_21015_0_0.png</td>\n",
       "      <td>1000083</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000143_21015_0_0.png</td>\n",
       "      <td>1000143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000150_21015_0_0.png</td>\n",
       "      <td>1000150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                image.id      eid  image.instance  image.array  \\\n",
       "0  1000058_21015_1_0.png  1000058               1            0   \n",
       "1  1000075_21015_0_0.png  1000075               0            0   \n",
       "2  1000083_21015_0_0.png  1000083               0            0   \n",
       "3  1000143_21015_0_0.png  1000143               0            0   \n",
       "4  1000150_21015_0_0.png  1000150               0            0   \n",
       "\n",
       "   age_at_imaging  genetic_sex  bmi_at_imaging  \n",
       "0       63.824176          0.0            36.8  \n",
       "1       64.000000          1.0            33.4  \n",
       "2       42.000000          1.0            26.9  \n",
       "3       48.000000          0.0            21.8  \n",
       "4       44.000000          0.0            19.6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute_df = pd.read_csv(attributes_path, sep='\\t')\n",
    "attribute_df = attribute_df[['image.id', 'eid', 'image.instance', 'image.array', 'age_at_imaging', 'genetic_sex','bmi_at_imaging']]\n",
    "attribute_df['Age_multi']=pd.cut(attribute_df['age_at_imaging'], bins=[0,50,60,70,100], labels=[0,1,2,3])\n",
    "attribute_df['Age_binary']=pd.cut(attribute_df['age_at_imaging'], bins=[0,58,100], labels=[0,1])\n",
    "attribute_df = attribute_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_df['genetic_sex'] = attribute_df['genetic_sex'].apply(lambda x: 'F' if x == 0 else ('M' if x == 1 else np.nan))\n",
    "attribute_df.rename(columns={'genetic_sex': 'Sex'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_df['bmi_cat']=pd.cut(attribute_df['bmi_at_imaging'], bins=[0,24,26.5,29.5,100], labels=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_df.rename(columns={'22032-0.0':'22032'}, inplace=True)\n",
    "attribute_df.rename(columns={'22032':'physical_activity'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_df.rename(columns={'26410-0.0':'26410'}, inplace=True)\n",
    "attribute_df['deprivation_index']=pd.cut(attribute_df['26410'], bins=[0,8,13,23,100], labels=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for location, will assume that if visits 1 2 or 3 are NA, they are at the same centre as visit 0\n",
    "attribute_df['54-1.0'].fillna(attribute_df['54-0.0'], inplace=True)\n",
    "attribute_df['54-2.0'].fillna(attribute_df['54-0.0'], inplace=True)\n",
    "attribute_df['54-3.0'].fillna(attribute_df['54-0.0'], inplace=True)\n",
    "\n",
    "attribute_df['54'] = attribute_df.apply(lambda x: x[f'54-{x[\"image.instance\"]}.0'], axis=1)\n",
    "attribute_df.drop(columns=['54-0.0','54-1.0','54-2.0','54-3.0'], inplace=True)\n",
    "mapping = {11014: 0, 11016: 1, 11018: 2, 11020: 3, 11021: 4, 11024: 5}\n",
    "attribute_df['Centre'] = attribute_df['54'].map(mapping)\n",
    "attribute_df.rename(columns={'54':'assessment_centre'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for alcohol, will just delete 1,2, and 3 as >80% are NA and will assume values haven't changed\n",
    "attribute_df.drop(columns=['1558-1.0','1558-2.0','1558-3.0'], inplace=True)\n",
    "attribute_df.rename(columns={'1558-0.0':'1558'}, inplace=True)\n",
    "attribute_df.rename(columns={'1558':'alcohol'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# less than 0.1% differences between first reported ethnicitity and other if reported, so will just keep first\n",
    "attribute_df['21000'] = attribute_df['21000-0.0']\n",
    "attribute_df['22006'] = attribute_df['22006-0.0']\n",
    "\n",
    "attribute_df['gen_ethnicity'] = attribute_df['22006'].apply(lambda x: 1 if x==1 else 0)\n",
    "\n",
    "attribute_df['Ethnicity'] = attribute_df['21000'].astype(str).str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust BP labels when individual is taking medication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get BP for each visit (as oppose to for each image)\n",
    "attribute_df['4080-0'] = attribute_df[['4080-0.0','4080-0.1']].mean(axis=1)\n",
    "attribute_df['4080-1'] = attribute_df[['4080-1.0','4080-1.1']].mean(axis=1)\n",
    "attribute_df['4080-2'] = attribute_df[['4080-2.0','4080-2.1']].mean(axis=1)\n",
    "attribute_df['4080-3'] = attribute_df[['4080-3.0','4080-3.1']].mean(axis=1)\n",
    "\n",
    "attribute_df['4079-0'] = attribute_df[['4079-0.0','4079-0.1']].mean(axis=1)\n",
    "attribute_df['4079-1'] = attribute_df[['4079-1.0','4079-1.1']].mean(axis=1)\n",
    "attribute_df['4079-2'] = attribute_df[['4079-2.0','4079-2.1']].mean(axis=1)\n",
    "attribute_df['4079-3'] = attribute_df[['4079-3.0','4079-3.1']].mean(axis=1)\n",
    "\n",
    "# if there is a nan value in any of those cols, need to replace by the mean of the other three cols\n",
    "cols = ['4080-0','4080-1','4080-2','4080-3']\n",
    "for col in cols:\n",
    "    attribute_df[col].fillna(attribute_df[cols].mean(axis=1), inplace=True)\n",
    "\n",
    "cols = ['4079-0','4079-1','4079-2','4079-3']\n",
    "for col in cols:\n",
    "    attribute_df[col].fillna(attribute_df[cols].mean(axis=1), inplace=True)\n",
    "# still about 5% of rows are Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid</th>\n",
       "      <th>54-0.0</th>\n",
       "      <th>54-1.0</th>\n",
       "      <th>54-2.0</th>\n",
       "      <th>54-3.0</th>\n",
       "      <th>1558-0.0</th>\n",
       "      <th>1558-1.0</th>\n",
       "      <th>1558-2.0</th>\n",
       "      <th>1558-3.0</th>\n",
       "      <th>4079-0.0</th>\n",
       "      <th>...</th>\n",
       "      <th>4080-2</th>\n",
       "      <th>4080-3</th>\n",
       "      <th>4079-0</th>\n",
       "      <th>4079-1</th>\n",
       "      <th>4079-2</th>\n",
       "      <th>4079-3</th>\n",
       "      <th>med-0</th>\n",
       "      <th>med-1</th>\n",
       "      <th>med-2</th>\n",
       "      <th>med-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000011</td>\n",
       "      <td>11008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>...</td>\n",
       "      <td>112.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000026</td>\n",
       "      <td>11001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>...</td>\n",
       "      <td>133.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>75.5</td>\n",
       "      <td>75.5</td>\n",
       "      <td>75.5</td>\n",
       "      <td>75.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000032</td>\n",
       "      <td>11001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>128.5</td>\n",
       "      <td>128.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000044</td>\n",
       "      <td>11018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>133.5</td>\n",
       "      <td>133.5</td>\n",
       "      <td>71.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000058</td>\n",
       "      <td>11006</td>\n",
       "      <td>11024.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.0</td>\n",
       "      <td>...</td>\n",
       "      <td>152.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>81.5</td>\n",
       "      <td>89.5</td>\n",
       "      <td>85.5</td>\n",
       "      <td>85.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502361</th>\n",
       "      <td>6024070</td>\n",
       "      <td>11020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>118.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502362</th>\n",
       "      <td>6024088</td>\n",
       "      <td>11005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>142.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502363</th>\n",
       "      <td>6024092</td>\n",
       "      <td>11004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>118.5</td>\n",
       "      <td>118.5</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502364</th>\n",
       "      <td>6024107</td>\n",
       "      <td>11018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>...</td>\n",
       "      <td>136.5</td>\n",
       "      <td>136.5</td>\n",
       "      <td>80.5</td>\n",
       "      <td>80.5</td>\n",
       "      <td>80.5</td>\n",
       "      <td>80.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502365</th>\n",
       "      <td>6024119</td>\n",
       "      <td>11017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>149.5</td>\n",
       "      <td>149.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502366 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            eid  54-0.0   54-1.0  54-2.0  54-3.0  1558-0.0  1558-1.0  \\\n",
       "0       1000011   11008      NaN     NaN     NaN       5.0       NaN   \n",
       "1       1000026   11001      NaN     NaN     NaN       2.0       NaN   \n",
       "2       1000032   11001      NaN     NaN     NaN       6.0       NaN   \n",
       "3       1000044   11018      NaN     NaN     NaN       5.0       NaN   \n",
       "4       1000058   11006  11024.0     NaN     NaN       1.0       1.0   \n",
       "...         ...     ...      ...     ...     ...       ...       ...   \n",
       "502361  6024070   11020      NaN     NaN     NaN       5.0       NaN   \n",
       "502362  6024088   11005      NaN     NaN     NaN       6.0       NaN   \n",
       "502363  6024092   11004      NaN     NaN     NaN       3.0       NaN   \n",
       "502364  6024107   11018      NaN     NaN     NaN       2.0       NaN   \n",
       "502365  6024119   11017      NaN     NaN     NaN       5.0       NaN   \n",
       "\n",
       "        1558-2.0  1558-3.0  4079-0.0  ...  4080-2  4080-3  4079-0  4079-1  \\\n",
       "0            NaN       NaN      76.0  ...   112.0   112.0    74.0    74.0   \n",
       "1            NaN       NaN      75.0  ...   133.0   133.0    75.5    75.5   \n",
       "2            NaN       NaN      73.0  ...   128.5   128.5    70.0    70.0   \n",
       "3            NaN       NaN      70.0  ...   133.5   133.5    71.0    71.0   \n",
       "4            NaN       NaN      79.0  ...   152.0   152.0    81.5    89.5   \n",
       "...          ...       ...       ...  ...     ...     ...     ...     ...   \n",
       "502361       NaN       NaN      62.0  ...   118.0   118.0    64.0    64.0   \n",
       "502362       NaN       NaN      93.0  ...   142.5   142.5    95.0    95.0   \n",
       "502363       NaN       NaN      77.0  ...   118.5   118.5    74.0    74.0   \n",
       "502364       NaN       NaN      78.0  ...   136.5   136.5    80.5    80.5   \n",
       "502365       NaN       NaN      82.0  ...   149.5   149.5    82.0    82.0   \n",
       "\n",
       "        4079-2  4079-3  med-0  med-1  med-2  med-3  \n",
       "0         74.0    74.0      0    0.0    0.0    0.0  \n",
       "1         75.5    75.5      0    0.0    0.0    0.0  \n",
       "2         70.0    70.0      1    1.0    1.0    1.0  \n",
       "3         71.0    71.0      0    0.0    0.0    0.0  \n",
       "4         85.5    85.5      0    0.0    0.0    0.0  \n",
       "...        ...     ...    ...    ...    ...    ...  \n",
       "502361    64.0    64.0      0    0.0    0.0    0.0  \n",
       "502362    95.0    95.0      0    0.0    0.0    0.0  \n",
       "502363    74.0    74.0      0    0.0    0.0    0.0  \n",
       "502364    80.5    80.5      0    0.0    0.0    0.0  \n",
       "502365    82.0    82.0      0    0.0    0.0    0.0  \n",
       "\n",
       "[502366 rows x 40 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medication_df = pd.read_csv('/well/papiez/users/hri611/python/MEDFAIR-PROJECT/MEDFAIR/ukbb_medication.txt', sep='\\t')\n",
    "# 6153 is for women, 6177 is for men\n",
    "# 2 is BP medication\n",
    "\n",
    "# 1 if any col that starts with '6153-0' or with '6177-0' contains a 2\n",
    "\n",
    "for i in range(4):\n",
    "    col_name_a = '6153-' + str(i)\n",
    "    col_name_b = '6177-' + str(i)\n",
    "    cols = [col for col in medication_df.columns if col.startswith(col_name_a) or col.startswith(col_name_b)]\n",
    "    medication_df[f'med-{i}'] = (medication_df[cols] == 2).any(axis=1).astype(int)\n",
    "\n",
    "# if taking medication at baseline assume they are also taking it later\n",
    "medication_df['med-1'] = medication_df.apply(lambda x: 1 if x['med-0'] == 1 else x['med-1'], axis=1)\n",
    "medication_df['med-2'] = medication_df.apply(lambda x: 1 if x['med-0'] == 1 else x['med-2'], axis=1)\n",
    "medication_df['med-3'] = medication_df.apply(lambda x: 1 if x['med-0'] == 1 else x['med-3'], axis=1)\n",
    "\n",
    "attribute_df = pd.merge(attribute_df,medication_df[['eid','med-0','med-1','med-2','med-3']],on='eid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 10 and 15 to DBP and SBP respectively\n",
    "\n",
    "cols = ['4080-0','4080-1','4080-2','4080-3'] # systolic BP\n",
    "for i in range(4):\n",
    "    med_col = 'med-' + str(i)\n",
    "    bp_col = cols[i]\n",
    "    attribute_df[bp_col] = attribute_df.apply(lambda x: x[bp_col]+15 if x[med_col] == 1 else x[bp_col], axis=1)\n",
    "\n",
    "cols = ['4079-0','4079-1','4079-2','4079-3'] # diastolic BP\n",
    "for i in range(4):\n",
    "    med_col = 'med-' + str(i)\n",
    "    bp_col = cols[i]\n",
    "    attribute_df[bp_col] = attribute_df.apply(lambda x: x[bp_col]+10 if x[med_col] == 1 else x[bp_col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_df['adjusted_4079'] = attribute_df.apply(lambda x: x['4079-0'] if x['image.instance'] == 0 else x['4079-1'] if x['image.instance'] == 1 else x['4079-2'] if x['image.instance'] == 2 else x['4079-3'], axis=1)\n",
    "attribute_df['adjusted_4080'] = attribute_df.apply(lambda x: x['4080-0'] if x['image.instance'] == 0 else x['4080-1'] if x['image.instance'] == 1 else x['4080-2'] if x['image.instance'] == 2 else x['4080-3'], axis=1)\n",
    "attribute_df['adjusted_high_bp'] = attribute_df.apply(lambda x: 1 if x.loc['adjusted_4079'] >= 80 or x.loc['adjusted_4080'] >= 130 or x['med-'+str(x['image.instance'])]==1 else 0, axis=1)\n",
    "attribute_df['binaryLabel'] = attribute_df['adjusted_high_bp']\n",
    "\n",
    "# replace nan values with mean sbp (about 0.2% of values)\n",
    "mean_sbp = attribute_df['adjusted_4080'].mean()\n",
    "attribute_df['adjusted_4080'] = attribute_df['adjusted_4080'].fillna(mean_sbp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add image paths and merge both dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_paths = [os.path.join(image_folder,x) for x in os.listdir(image_folder) if 'png' in x]\n",
    "\n",
    "image_paths = pd.DataFrame({'image_path':images_paths})\n",
    "image_paths['image.id'] = image_paths['image_path'].apply(lambda x: x.split('/')[-1])\n",
    "image_paths['eid']=image_paths['image.id'].apply(lambda x: x.split('_')[0]).astype(int)\n",
    "image_paths['image.instance']=image_paths['image.id'].apply(lambda x: x.split('_')[2]).astype(int)\n",
    "image_paths['image.array']=image_paths['image.id'].apply(lambda x: x.split('_')[3].split('.')[0]).astype(int)\n",
    "\n",
    "# add image paths to metadata df (inner join to keep only images with metadata and images you have)\n",
    "all_metadata_df = pd.merge(attribute_df, image_paths, on=['image.id','eid','image.array','image.instance'], how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rare ethnicity values and one assessment centre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metadata_df = all_metadata_df[~all_metadata_df['Ethnicity'].isin(['n', '6', '-'])]\n",
    "all_metadata_df.loc[all_metadata_df['Ethnicity']=='5', 'Ethnicity'] = '3'\n",
    "all_metadata_df.loc[all_metadata_df['Ethnicity']=='4', 'Ethnicity'] = '0'\n",
    "all_metadata_df['Ethnicity'] = all_metadata_df['Ethnicity'].astype(int)\n",
    "\n",
    "all_metadata_df = all_metadata_df[~all_metadata_df['54'].isin([11022.0])] # drops about 0.2% of images\n",
    "\n",
    "all_metadata_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_811(all_meta, patient_ids):\n",
    "    sub_train, sub_val_test = train_test_split(patient_ids, test_size=0.2, random_state=0)\n",
    "    sub_val, sub_test = train_test_split(sub_val_test, test_size=0.5, random_state=0)\n",
    "    train_meta = all_meta[all_meta.eid.isin(sub_train)]\n",
    "    val_meta = all_meta[all_meta.eid.isin(sub_val)]\n",
    "    test_meta = all_meta[all_meta.eid.isin(sub_test)]\n",
    "    return train_meta, val_meta, test_meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train, sub_val, sub_test = split_811(all_metadata_df, np.unique(all_metadata_df['eid'])) # stratify by patient id\n",
    "sub_train.to_csv(train_imgs_path)\n",
    "sub_val.to_csv(val_imgs_path)\n",
    "sub_test.to_csv(test_imgs_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save PKL files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data_split = '' # train, val, test csvs\n",
    "save_path = ''\n",
    "\n",
    "images = []\n",
    "\n",
    "df = pd.read_csv(path_to_data_split)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    \n",
    "    img = cv2.imread(df.iloc[i]['image_path'],cv2.IMREAD_GRAYSCALE) #so it only has one channel\n",
    "    \n",
    "    # resize to the input size in advance to save time during training\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    images.append(img)\n",
    "\n",
    "\n",
    "with open(save_path,'wb') as f:\n",
    "    pickle.dump(images, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
